num_of_random_dilations: 2, 12 haben sehr gut performt



Hallo Patrick,

ich konnte weitere Fortschritte machen. Habe nun Dilation auch in den Shapelet Transform Classifier eingebaut und mein Benchmark testet nun verschiedene Parameterkombinationen. Für CBOSS konnte ich so einige Parameterkombination herausfinden, die eine gleich Genauigkeit haben aber schneller sind. Ich habe das CSV mit den average Werten von den verschiedenen Parametern angehängt.

Für Shapelet und TimeSeriesForest laufen die Benchmarks gerade. Leider sind die gruenau5-8 momentan alle häufig sehr ausgelastet.

Hier einmal die Parameterkombinationen die ich jeweils teste: (vielleicht fallen dir hier noch andere sinnvolle Werte ein)

BOSS:
def generate_parameters():
    parameters = [
        [cboss_num_of_random_dilations, cboss_win_lengths, cboss_norm_options, cboss_word_lengths, cboss_alphabet_size, cboss_feature_selection, cboss_max_feature_count]
        for cboss_num_of_random_dilations in range(2, 101, 10)
        for w, cboss_win_lengths in enumerate([[28, 24, 20, 16, 12]]) # TODO hier eventuell noch bessere werte finden bzw. andere ausprobieren
        for n, cboss_norm_options in enumerate([[True,False]])
        for g, cboss_word_lengths in enumerate([[4,6], [6], [6,8], [8]])
        for k, cboss_alphabet_size in enumerate([2, 4, 6])
        for i, cboss_feature_selection in enumerate(["none", "chi2", "random"])
        for p, cboss_max_feature_count in enumerate([256, 512])
    ]
    return parameters
    
TimeSeriesForest:
def generate_parameters():
    parameters = [
        [tsf_n_intervals_prop, tsf_interval_length_prop, tsf_num_of_random_dilations, tsf_n_estimators]
        for a, tsf_n_intervals_prop in enumerate([0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.8, 2.0, 5.0, 10.0])
        for b, tsf_interval_length_prop in enumerate([1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4])
        for c, tsf_num_of_random_dilations in enumerate([1, 20, 50, 100])
        for d, tsf_n_estimators in enumerate([100, 200, 300])
    ]
    return parameters
    
Shapelet:
def generate_parameters():
    parameters = [
        [stc_n_shapelet_samples, stc_max_shapelet_length, stc_max_shapelets]
        for a, stc_n_shapelet_samples in enumerate([10000, 15000, 20000, 25000, 30000])
        for b, stc_max_shapelet_length in enumerate([None, 7, 9, 11])
        for c, stc_max_shapelets in enumerate([None, 1000, 3000, 5000, 10000, 20000])
    ]
    return parameters
    
    
Bei cBOSS scheinen eher kleine Werte wie 2 und 12 num_of_random_dilations sinnvoll zu sein. Hier teste ich im nächsten benchmark dann nochmal mehr Werte in dem Bereich von 2-20.

Wenn ich nun meine besten Classifier für diesen kleinen Datensatz gefunden habe, teste ich diese nochmal gegen (fast) alle Datensaätze aus dem UCR Datensatz. Mit diesen Ergebnissen schreibe ich dann die Ausarbeitung richtig?

Für die Ausarbeitung wollte ich die Inhalte aus dem Exposé wiederverwenden und um einiges erweitern. Hier meine Idee der groben Struktur:
- Introduction
- Background and Definitions
- State-Of-the-Art Classifier (diesmal meine Classifier etwas genauer beschreiben)
- Objective
- Methods (hier dann zusätzlich auch beschreiben wo genau in den jeweiligen Algorithmen Dilation eingebaut wurde?)
- Evaluation:
	- Getestete Parameter beschreiben und Auswahl begründen
	- Ergebnisse aus den Benchmarks darstellen und Fazit daraus ziehen

Beste Grüße
Michael
