{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "from sktime.classification.dictionary_based import BOSSEnsembleDilation\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifierDilation\n",
    "from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "from sktime.classification.shapelet_based import ShapeletTransformClassifierDilation\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sktime.benchmarking.data import UEADataset, make_datasets\n",
    "from sktime.benchmarking.evaluation import Evaluator\n",
    "from sktime.benchmarking.metrics import PairwiseMetric\n",
    "from sktime.benchmarking.orchestration import Orchestrator\n",
    "from sktime.benchmarking.results import HDDResults\n",
    "from sktime.benchmarking.strategies import TSCStrategy\n",
    "from sktime.benchmarking.tasks import TSCTask\n",
    "\n",
    "from sktime.series_as_features.model_selection import PresplitFilesCV\n",
    "\n",
    "from convst.classifiers import R_DST_Ridge\n",
    "from convst.utils.dataset_utils import load_sktime_dataset_split\n",
    "\n",
    "from sktime.datasets import load_from_tsfile\n",
    "from sktime.datatypes._panel._convert import from_nested_to_3d_numpy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_datasets = [\n",
    "    # 'ACSF1',\n",
    "    # 'Adiac',\n",
    "    # 'AllGestureWiimoteX',\n",
    "    # 'AllGestureWiimoteY',\n",
    "    # 'AllGestureWiimoteZ',\n",
    "    \"ArrowHead\",\n",
    "    \"Beef\",\n",
    "    \"BeetleFly\",\n",
    "    \"BirdChicken\",\n",
    "    # 'BME',\n",
    "    \"Car\",\n",
    "    \"CBF\",\n",
    "    # 'Chinatown',\n",
    "    # 'ChlorineConcentration',\n",
    "    # 'CinCECGTorso',\n",
    "    \"Coffee\",\n",
    "    # 'Computers',\n",
    "    # 'CricketX',\n",
    "    # 'CricketY',\n",
    "    # 'CricketZ',\n",
    "    # 'Crop',\n",
    "    \"DiatomSizeReduction\",\n",
    "    \"DistalPhalanxOutlineAgeGroup\",\n",
    "    \"DistalPhalanxOutlineCorrect\",\n",
    "    \"DistalPhalanxTW\",\n",
    "    # 'DodgerLoopDay',\n",
    "    # 'DodgerLoopGame',\n",
    "    # 'DodgerLoopWeekend',\n",
    "    # 'Earthquakes',\n",
    "    \"ECG200\",\n",
    "    # 'ECG5000',\n",
    "    \"ECGFiveDays\",\n",
    "    # 'ElectricDevices',\n",
    "    # 'EOGHorizontalSignal',\n",
    "    # 'EOGVerticalSignal',\n",
    "    # 'EthanolLevel',\n",
    "    # 'FaceAll',\n",
    "    # \"FaceFour\",\n",
    "    # 'FacesUCR',\n",
    "    # 'FiftyWords',\n",
    "    # 'Fish',\n",
    "    # 'FordA',\n",
    "    # 'FordB',\n",
    "    # 'FreezerRegularTrain',\n",
    "    # 'FreezerSmallTrain',\n",
    "    # 'Fungi',\n",
    "    # 'GestureMidAirD1',\n",
    "    # 'GestureMidAirD2',\n",
    "    # 'GestureMidAirD3',\n",
    "    # 'GesturePebbleZ1',\n",
    "    # 'GesturePebbleZ2',\n",
    "    #####\"Gun_Point\",\n",
    "    # 'GunPointAgeSpan',\n",
    "    # 'GunPointMaleVersusFemale',\n",
    "    # 'GunPointOldVersusYoung',\n",
    "    # 'Ham',\n",
    "    # 'HandOutlines',\n",
    "    # 'Haptics',\n",
    "    # 'Herring',\n",
    "    # 'HouseTwenty',\n",
    "    # 'InlineSkate',\n",
    "    # 'InsectEPGRegularTrain',\n",
    "    # 'InsectEPGSmallTrain',\n",
    "    # 'InsectWingbeatSound',\n",
    "    \"ItalyPowerDemand\",\n",
    "    # 'LargeKitchenAppliances',\n",
    "    # 'Lightning2',\n",
    "    # 'Lightning7',\n",
    "    # 'Mallat',\n",
    "    # 'Meat',\n",
    "    # 'MedicalImages',\n",
    "    # 'MelbournePedestrian',\n",
    "    \"MiddlePhalanxOutlineAgeGroup\",\n",
    "    \"MiddlePhalanxOutlineCorrect\",\n",
    "    \"MiddlePhalanxTW\",\n",
    "    # 'Missing_value_and_variable_length_datasets_adjusted',\n",
    "    # 'MixedShapesRegularTrain',\n",
    "    # 'MixedShapesSmallTrain',\n",
    "    # 'MoteStrain',\n",
    "    # 'NonInvasiveFetalECGThorax1',\n",
    "    # 'NonInvasiveFetalECGThorax2',\n",
    "    \"OliveOil\",\n",
    "    # 'OSULeaf',\n",
    "    # 'PhalangesOutlinesCorrect',\n",
    "    # 'Phoneme',\n",
    "    # 'PickupGestureWiimoteZ',\n",
    "    # 'PigAirwayPressure',\n",
    "    # 'PigArtPressure',\n",
    "    # 'PigCVP',\n",
    "    # 'PLAID',\n",
    "    \"Plane\",\n",
    "    # 'PowerCons',\n",
    "    \"ProximalPhalanxOutlineAgeGroup\",\n",
    "    \"ProximalPhalanxOutlineCorrect\",\n",
    "    \"ProximalPhalanxTW\",\n",
    "    # 'RefrigerationDevices',\n",
    "    # 'Rock',\n",
    "    # 'ScreenType',\n",
    "    # 'SemgHandGenderCh2',\n",
    "    # 'SemgHandMovementCh2',\n",
    "    # 'SemgHandSubjectCh2',\n",
    "    # 'ShakeGestureWiimoteZ',\n",
    "    # 'ShapeletSim',\n",
    "    # 'ShapesAll',\n",
    "    # 'SmallKitchenAppliances',\n",
    "    # 'SmoothSubspace',\n",
    "    ####\"SonyAIBORobot Surface\",\n",
    "    ####\"SonyAIBORobot SurfaceII\",\n",
    "    # 'StarLightCurves',\n",
    "    # 'Strawberry',\n",
    "    # 'SwedishLeaf',\n",
    "    # 'Symbols',\n",
    "    \"SyntheticControl\",\n",
    "    # 'ToeSegmentation1',\n",
    "    # 'ToeSegmentation2',\n",
    "    # 'Trace',\n",
    "    \"TwoLeadECG\",\n",
    "    # 'TwoPatterns',\n",
    "    # 'UMD',\n",
    "    # 'UWaveGestureLibraryAll',\n",
    "    # 'UWaveGestureLibraryX',\n",
    "    # 'UWaveGestureLibraryY',\n",
    "    # 'UWaveGestureLibraryZ',\n",
    "    # 'Wafer',\n",
    "    \"Wine\",\n",
    "    # 'WordSynonyms',\n",
    "    # 'Worms',\n",
    "    # 'WormsTwoClass',\n",
    "    # 'Yoga'\n",
    "\n",
    "    \"DiatomSizeReduction\",\n",
    "    \"DistalPhalanxOutlineAgeGroup\",\n",
    "    \"DistalPhalanxOutlineCorrect\",\n",
    "    \"DistalPhalanxTW\",\n",
    "    \"ECG200\",\n",
    "    \"ECGFiveDays\",\n",
    "    \"MiddlePhalanxOutlineAgeGroup\",\n",
    "    \"MiddlePhalanxOutlineCorrect\",\n",
    "    \"MiddlePhalanxTW\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [7, 9, 11]\n",
    "num_of_random_dilations = 200\n",
    "\n",
    "DATA_PATH = \"./Univariate_ts\"\n",
    "datasets = make_datasets(\n",
    "    path=DATA_PATH, dataset_cls=UEADataset, names=[\"ArrowHead\"] #used_datasets\n",
    ")\n",
    "#[\"ArrowHead\", \"Car\", \"CBF\", \"Coffee\"]\n",
    "\n",
    "clfs = [\n",
    "    #[BOSSEnsemble(), \"BOSS\"],\n",
    "    #[BOSSEnsembleDilation(num_of_random_dilations=num_of_random_dilations, window_sizes = window_sizes), \"BOSS_Dilation\"],\n",
    "    [TimeSeriesForestClassifier(), \"TimeSeriesForest\"],\n",
    "    [TimeSeriesForestClassifierDilation(), \"TimeSeriesForest_Dilation\"],\n",
    "    #[ShapeletTransformClassifier(estimator=RidgeClassifierCV()), \"ShapeletTransform+RidgeClassifier\"], \n",
    "    #[ShapeletTransformClassifier(), \"ShapeletTransform\"], # uses RandomForest from sktime\n",
    "    #TSCStrategy(ShapeletTransformClassifierDilation(), name=\"ShapeletTransformDilation\"),\n",
    "    [R_DST_Ridge(), \"RDST\"], # uses RidgeClassifierCV from scikitlearn\n",
    "]\n",
    "\n",
    "results = pd.DataFrame(columns=[        \n",
    "        \"Classifier\",\n",
    "        \"Dataset\",\n",
    "        \"Accuracy\",\n",
    "        \"Fit-Time\",\n",
    "        \"Predict-Time\",])\n",
    "\n",
    "av_results = pd.DataFrame(columns=[        \n",
    "        \"Classifier\",\n",
    "        \"Dataset\",\n",
    "        \"Accuracy\",\n",
    "        \"Fit-Time\",\n",
    "        \"Predict-Time\",])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf TimeSeriesForest done\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/michael/git/dilation_evaluation/main.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michael/git/dilation_evaluation/main.ipynb#ch0000005?line=17'>18</a>\u001b[0m \u001b[39m# z normalize data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michael/git/dilation_evaluation/main.ipynb#ch0000005?line=18'>19</a>\u001b[0m \u001b[39m#X_train = zscore(X_train, axis=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michael/git/dilation_evaluation/main.ipynb#ch0000005?line=19'>20</a>\u001b[0m \u001b[39m#X_test = zscore(X_test, axis=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michael/git/dilation_evaluation/main.ipynb#ch0000005?line=21'>22</a>\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/michael/git/dilation_evaluation/main.ipynb#ch0000005?line=22'>23</a>\u001b[0m clf[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michael/git/dilation_evaluation/main.ipynb#ch0000005?line=23'>24</a>\u001b[0m fit_time \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m fit_time, \u001b[39m5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michael/git/dilation_evaluation/main.ipynb#ch0000005?line=25'>26</a>\u001b[0m predict_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n",
      "File \u001b[0;32m~/git/sktime_dilation/sktime/classification/interval_based/_tsf_dilation.py:96\u001b[0m, in \u001b[0;36mTimeSeriesForestClassifierDilation.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     89\u001b[0m     \u001b[39m\"\"\"Wrap fit to call BaseClassifier.fit.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[39m    This is a fix to get around the problem with multiple inheritance. The\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m    albeit a little hacky.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m BaseClassifier\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m, X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/git/sktime_dilation/sktime/classification/base.py:173\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m index, class_val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_):\n\u001b[1;32m    172\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_dictionary[class_val] \u001b[39m=\u001b[39m index\n\u001b[0;32m--> 173\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n\u001b[1;32m    174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_time_ \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)) \u001b[39m-\u001b[39m start\n\u001b[1;32m    175\u001b[0m \u001b[39m# this should happen last\u001b[39;00m\n",
      "File \u001b[0;32m~/git/sktime_dilation/sktime/classification/interval_based/_tsf_dilation.py:107\u001b[0m, in \u001b[0;36mTimeSeriesForestClassifierDilation._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m--> 107\u001b[0m     BaseTimeSeriesForestDilation\u001b[39m.\u001b[39;49m_fit(\u001b[39mself\u001b[39;49m, X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my)\n",
      "File \u001b[0;32m~/git/sktime_dilation/sktime/series_as_features/base/estimators/interval_based/_tsf_dilation.py:108\u001b[0m, in \u001b[0;36mBaseTimeSeriesForestDilation._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_interval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseries_length\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintervals_ \u001b[39m=\u001b[39m [\n\u001b[1;32m    104\u001b[0m     _get_intervals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_intervals, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_interval, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseries_length, rng)\n\u001b[1;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators)\n\u001b[1;32m    106\u001b[0m ]\n\u001b[0;32m--> 108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs)(\n\u001b[1;32m    109\u001b[0m     delayed(_fit_estimator)(\n\u001b[1;32m    110\u001b[0m         _clone_estimator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_estimator, rng), X, y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintervals_[i]\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators) \u001b[39m# n_estimator: Number of estimators to build for the ensemble\u001b[39;49;00m\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_fitted \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/git/sktime_dilation/sktime/series_as_features/base/estimators/interval_based/_tsf_dilation.py:177\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, intervals)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_estimator\u001b[39m(estimator, X, y, intervals):\n\u001b[1;32m    176\u001b[0m     \u001b[39m\"\"\"Fit an estimator on input data (X, y).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     transformed_x \u001b[39m=\u001b[39m _transform(X, intervals)\n\u001b[1;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39mfit(transformed_x, y)\n",
      "File \u001b[0;32m~/git/sktime_dilation/sktime/series_as_features/base/estimators/interval_based/_tsf_dilation.py:143\u001b[0m, in \u001b[0;36m_transform\u001b[0;34m(X, intervals)\u001b[0m\n\u001b[1;32m    140\u001b[0m transformed_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(shape\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m \u001b[39m*\u001b[39m n_intervals, n_instances), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_intervals):\n\u001b[1;32m    142\u001b[0m     \u001b[39m#X_dilated = self.dilation(X, j[2]) # MOD \u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     d \u001b[39m=\u001b[39m j[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    144\u001b[0m     X_dilated \u001b[39m=\u001b[39m X[:, :, \u001b[39m0\u001b[39m::d]\n\u001b[1;32m    145\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, d):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "# clean data from previous runs\n",
    "results = results[0:0]\n",
    "av_results = av_results[0:0]\n",
    "\n",
    "for clf in clfs:\n",
    "    for dataset in datasets:\n",
    "        X_train, y_train = load_from_tsfile(dataset._train_path)\n",
    "        X_test, y_test = load_from_tsfile(dataset._test_path)\n",
    "\n",
    "        X_train = from_nested_to_3d_numpy(X_train)\n",
    "        X_test = from_nested_to_3d_numpy(X_test)\n",
    "\n",
    "        # Convert class labels to make sure they are between 0,n_classes\n",
    "        le = LabelEncoder().fit(y_train)\n",
    "        y_train = le.transform(y_train)\n",
    "        y_test = le.transform(y_test)\n",
    "        \n",
    "        # z normalize data\n",
    "        #X_train = zscore(X_train, axis=1)\n",
    "        #X_test = zscore(X_test, axis=1)\n",
    "\n",
    "        fit_time = time.process_time()\n",
    "        clf[0].fit(X_train, y_train)\n",
    "        fit_time = np.round(time.process_time() - fit_time, 5)\n",
    "\n",
    "        predict_time = time.process_time()\n",
    "        y_pred = clf[0].predict(X_test)\n",
    "        pred_time = np.round(time.process_time() - predict_time, 5)\n",
    "\n",
    "        acc = np.round(accuracy_score(y_test, y_pred), 5)\n",
    "\n",
    "        results.loc[len(results)] = [clf[1], dataset.name, acc, fit_time, pred_time]\n",
    "\n",
    "    results_from_clf = results.loc[results[\"Classifier\"] == clf[1]]\n",
    "    av_acc = results_from_clf[\"Accuracy\"].mean()\n",
    "    av_fit_time = results_from_clf[\"Fit-Time\"].mean()\n",
    "    av_pred_time = results_from_clf[\"Predict-Time\"].mean()\n",
    "    av_results.loc[len(results)] = [clf[1], \"ALL_AVERAGE\", av_acc, av_fit_time, av_pred_time]\n",
    "    print(f\"clf {clf[1]} done\")\n",
    "\n",
    "results = results.append(av_results, ignore_index=True)\n",
    "results.to_csv(\"results.csv\", index=None)\n",
    "print(av_results)\n",
    "\n",
    "# TODO random dilation wirklich random? Oder muss ich den seed neu setzen?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5e8a44a3d7d6b224416d51d7970e813dc6f6a515ebedecba73c2d67b35043e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
