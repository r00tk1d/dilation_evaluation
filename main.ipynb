{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sktime.classification.dictionary_based import ContractableBOSS\n",
    "from sktime.classification.dictionary_based import ContractableBOSSDilation\n",
    "from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "from sktime.classification.dictionary_based import BOSSEnsembleDilation\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifierDilation\n",
    "#from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "#from sktime.classification.shapelet_based import ShapeletTransformClassifierDilation\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sktime.benchmarking.data import UEADataset, make_datasets\n",
    "\n",
    "from convst.classifiers import R_DST_Ridge\n",
    "from convst.utils.dataset_utils import load_sktime_dataset_split\n",
    "\n",
    "from sktime.datasets import load_from_tsfile\n",
    "from sktime.datatypes._panel._convert import from_nested_to_3d_numpy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_datasets = [\n",
    "    # 'ACSF1',\n",
    "    # 'Adiac',\n",
    "    # 'AllGestureWiimoteX',\n",
    "    # 'AllGestureWiimoteY',\n",
    "    # 'AllGestureWiimoteZ',\n",
    "    \"ArrowHead\",\n",
    "    \"Beef\",\n",
    "    \"BeetleFly\",\n",
    "    \"BirdChicken\",\n",
    "    # 'BME',\n",
    "    \"Car\",\n",
    "    \"CBF\",\n",
    "    # 'Chinatown',\n",
    "    # 'ChlorineConcentration',\n",
    "    # 'CinCECGTorso',\n",
    "    \"Coffee\",\n",
    "    # 'Computers',\n",
    "    # 'CricketX',\n",
    "    # 'CricketY',\n",
    "    # 'CricketZ',\n",
    "    # 'Crop',\n",
    "    \"DiatomSizeReduction\",\n",
    "    \"DistalPhalanxOutlineAgeGroup\",\n",
    "    \"DistalPhalanxOutlineCorrect\",\n",
    "    \"DistalPhalanxTW\",\n",
    "    # 'DodgerLoopDay',\n",
    "    # 'DodgerLoopGame',\n",
    "    # 'DodgerLoopWeekend',\n",
    "    # 'Earthquakes',\n",
    "    \"ECG200\",\n",
    "    # 'ECG5000',\n",
    "    \"ECGFiveDays\",\n",
    "    # 'ElectricDevices',\n",
    "    # 'EOGHorizontalSignal',\n",
    "    # 'EOGVerticalSignal',\n",
    "    # 'EthanolLevel',\n",
    "    # 'FaceAll',\n",
    "    # \"FaceFour\",\n",
    "    # 'FacesUCR',\n",
    "    # 'FiftyWords',\n",
    "    # 'Fish',\n",
    "    # 'FordA',\n",
    "    # 'FordB',\n",
    "    # 'FreezerRegularTrain',\n",
    "    # 'FreezerSmallTrain',\n",
    "    # 'Fungi',\n",
    "    # 'GestureMidAirD1',\n",
    "    # 'GestureMidAirD2',\n",
    "    # 'GestureMidAirD3',\n",
    "    # 'GesturePebbleZ1',\n",
    "    # 'GesturePebbleZ2',\n",
    "    #####\"Gun_Point\",\n",
    "    # 'GunPointAgeSpan',\n",
    "    # 'GunPointMaleVersusFemale',\n",
    "    # 'GunPointOldVersusYoung',\n",
    "    # 'Ham',\n",
    "    # 'HandOutlines',\n",
    "    # 'Haptics',\n",
    "    # 'Herring',\n",
    "    # 'HouseTwenty',\n",
    "    # 'InlineSkate',\n",
    "    # 'InsectEPGRegularTrain',\n",
    "    # 'InsectEPGSmallTrain',\n",
    "    # 'InsectWingbeatSound',\n",
    "    \"ItalyPowerDemand\",\n",
    "    # 'LargeKitchenAppliances',\n",
    "    # 'Lightning2',\n",
    "    # 'Lightning7',\n",
    "    # 'Mallat',\n",
    "    # 'Meat',\n",
    "    # 'MedicalImages',\n",
    "    # 'MelbournePedestrian',\n",
    "    \"MiddlePhalanxOutlineAgeGroup\",\n",
    "    \"MiddlePhalanxOutlineCorrect\",\n",
    "    \"MiddlePhalanxTW\",\n",
    "    # 'Missing_value_and_variable_length_datasets_adjusted',\n",
    "    # 'MixedShapesRegularTrain',\n",
    "    # 'MixedShapesSmallTrain',\n",
    "    # 'MoteStrain',\n",
    "    # 'NonInvasiveFetalECGThorax1',\n",
    "    # 'NonInvasiveFetalECGThorax2',\n",
    "    \"OliveOil\",\n",
    "    # 'OSULeaf',\n",
    "    # 'PhalangesOutlinesCorrect',\n",
    "    # 'Phoneme',\n",
    "    # 'PickupGestureWiimoteZ',\n",
    "    # 'PigAirwayPressure',\n",
    "    # 'PigArtPressure',\n",
    "    # 'PigCVP',\n",
    "    # 'PLAID',\n",
    "    \"Plane\",\n",
    "    # 'PowerCons',\n",
    "    \"ProximalPhalanxOutlineAgeGroup\",\n",
    "    \"ProximalPhalanxOutlineCorrect\",\n",
    "    \"ProximalPhalanxTW\",\n",
    "    # 'RefrigerationDevices',\n",
    "    # 'Rock',\n",
    "    # 'ScreenType',\n",
    "    # 'SemgHandGenderCh2',\n",
    "    # 'SemgHandMovementCh2',\n",
    "    # 'SemgHandSubjectCh2',\n",
    "    # 'ShakeGestureWiimoteZ',\n",
    "    # 'ShapeletSim',\n",
    "    # 'ShapesAll',\n",
    "    # 'SmallKitchenAppliances',\n",
    "    # 'SmoothSubspace',\n",
    "    ####\"SonyAIBORobot Surface\",\n",
    "    ####\"SonyAIBORobot SurfaceII\",\n",
    "    # 'StarLightCurves',\n",
    "    # 'Strawberry',\n",
    "    # 'SwedishLeaf',\n",
    "    # 'Symbols',\n",
    "    \"SyntheticControl\",\n",
    "    # 'ToeSegmentation1',\n",
    "    # 'ToeSegmentation2',\n",
    "    # 'Trace',\n",
    "    \"TwoLeadECG\",\n",
    "    # 'TwoPatterns',\n",
    "    # 'UMD',\n",
    "    # 'UWaveGestureLibraryAll',\n",
    "    # 'UWaveGestureLibraryX',\n",
    "    # 'UWaveGestureLibraryY',\n",
    "    # 'UWaveGestureLibraryZ',\n",
    "    # 'Wafer',\n",
    "    \"Wine\",\n",
    "    # 'WordSynonyms',\n",
    "    # 'Worms',\n",
    "    # 'WormsTwoClass',\n",
    "    # 'Yoga'\n",
    "\n",
    "    # \"DiatomSizeReduction\",\n",
    "    # \"DistalPhalanxOutlineAgeGroup\",\n",
    "    # \"DistalPhalanxOutlineCorrect\",\n",
    "    # \"DistalPhalanxTW\",\n",
    "    # \"ECG200\",\n",
    "    # \"ECGFiveDays\",\n",
    "    # \"MiddlePhalanxOutlineAgeGroup\",\n",
    "    # \"MiddlePhalanxOutlineCorrect\",\n",
    "    # \"MiddlePhalanxTW\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./Univariate_ts\"\n",
    "datasets = make_datasets(\n",
    "    path=DATA_PATH, dataset_cls=UEADataset, names=used_datasets\n",
    ")\n",
    "# [\"ArrowHead\", \"Car\", \"CBF\", \"Coffee\"]\n",
    "# [\"ArrowHead\"]\n",
    "\n",
    "# clfs hyperparameter:\n",
    "# ContractableBOSS\n",
    "cboss_num_of_random_dilations = 50 # TODO noch einbauen\n",
    "cboss_win_lengths = [32, 28, 24, 20, 16] #  picked randomly\n",
    "cboss_norm_options = [True, False]\n",
    "cboss_word_lengths = [8] \n",
    "cboss_alphabet_size = 2\n",
    "cboss_feature_selection = \"none\" # {\"chi2\", \"none\", \"random\"} Sets the feature selections strategy to be used. Chi2 reduces the number of words significantly and is thus much faster (preferred). Random also reduces the number significantly. None applies not feature selection and yields large bag of words, e.g. much memory may be needed.\n",
    "cboss_max_feature_count = 256 # default=256, If feature_selection=random is chosen, this parameter defines the number of randomly chosen unique words used.\n",
    "#n_parameter_samples = \n",
    "cboss_total_feature_count = cboss_num_of_random_dilations * min(cboss_alphabet_size ** cboss_word_lengths[0], cboss_max_feature_count) # sollte bei 10.000-30.000 liegen\n",
    "# TODO 10.000 features pro classifier im Ensemble? Oder Gesamt? (ich denke pro classifier im Ensemble)\n",
    "\n",
    "# def _unique_parameters(max_window, win_inc):\n",
    "#     possible_parameters = [\n",
    "#         [win_size, word_len, normalise]\n",
    "#         for n, normalise in enumerate(self._norm_options)\n",
    "#         for win_size in range(self.min_window, max_window + 1, win_inc)\n",
    "#         for g, word_len in enumerate(self._word_lengths)\n",
    "#     ]\n",
    "\n",
    "#     return possible_parameters\n",
    "\n",
    "cboss_results_cols = [        \n",
    "        \"Classifier\",\n",
    "        \"Dataset\",\n",
    "        \"Accuracy\",\n",
    "        \"Fit-Time\",\n",
    "        \"Predict-Time\",\n",
    "        \"total_feature_count\",\n",
    "        \"num_of_random_dilations\",\n",
    "        \"win_lengths\",\n",
    "        \"norm_options\",\n",
    "        \"word_lengths\",\n",
    "        \"alphabet_size\",\n",
    "        \"feature_selection\",\n",
    "        \"max_feature_count\"]\n",
    "\n",
    "\n",
    "\n",
    "# TSFDilation:\n",
    "tsf_min_interval = 3\n",
    "tsf_n_intervals_prop = 0.8\n",
    "# TODO relevant? tsf_num_of_random_dilations = 200\n",
    "\n",
    "tsf_results_cols = [        \n",
    "        \"Classifier\",\n",
    "        \"Dataset\",\n",
    "        \"Accuracy\",\n",
    "        \"Fit-Time\",\n",
    "        \"Predict-Time\",\n",
    "        \"min_interval\",\n",
    "        \"n_intervals_prop\",]\n",
    "\n",
    "#[ClassifierFunction, ClassifierName, result_col_names, hyperparameterForResultsCSV]\n",
    "cboss_params = {\n",
    "    \"num_of_random_dilations\": cboss_num_of_random_dilations, \n",
    "    \"win_lengths\": cboss_win_lengths, \n",
    "    \"norm_options\": cboss_norm_options, \n",
    "    \"word_lengths\": cboss_word_lengths,\n",
    "    \"alphabet_size\": cboss_alphabet_size,\n",
    "    \"feature_selection\": cboss_feature_selection,\n",
    "    \"max_feature_count\": cboss_max_feature_count,}\n",
    "clfs = [\n",
    "    [ContractableBOSS(), \"CBOSS\", cboss_results_cols, [\"NULL\", \"NULL\", \"[True, False]\", \"[16, 14, 12, 10, 8]\", \"4\", \"none\", \"256\"]],\n",
    "    [ContractableBOSSDilation(**cboss_params), \"CBOSS_Dilation\", cboss_results_cols, list(cboss_params.values())],\n",
    "    #[TimeSeriesForestClassifier(), \"TimeSeriesForest\", tsf_results_cols, [3, 1]],\n",
    "    #[TimeSeriesForestClassifierDilation(min_interval=tsf_min_interval, n_intervals_prop=tsf_n_intervals_prop), \"TimeSeriesForest_Dilation\",  tsf_results_cols, \\\n",
    "    #    [str(tsf_min_interval), str(tsf_n_intervals_prop)]],\n",
    "    \n",
    "    #[ShapeletTransformClassifier(estimator=RidgeClassifierCV()), \"ShapeletTransform+RidgeClassifier\", shapelet_results_cols, [\"DEFAULT\"]], \n",
    "    #[ShapeletTransformClassifier(), \"ShapeletTransform\", shapelet_results_cols, [\"DEFAULT\"]], # uses RandomForest from sktime\n",
    "    #[ShapeletTransformClassifierDilation(), \"ShapeletTransformDilation\", shapelet_results_cols, [\"EDIT ME\"]],\n",
    "    #[R_DST_Ridge(), \"RDST\", RDST_results_cols, \"DEFAULT\"], # uses RidgeClassifierCV from scikitlearn\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf CBOSS dataset ArrowHead done\n",
      "clf CBOSS dataset Beef done\n",
      "clf CBOSS dataset BeetleFly done\n",
      "clf CBOSS dataset BirdChicken done\n",
      "clf CBOSS dataset Car done\n",
      "clf CBOSS dataset CBF done\n",
      "clf CBOSS dataset Coffee done\n",
      "clf CBOSS dataset DiatomSizeReduction done\n",
      "clf CBOSS dataset DistalPhalanxOutlineAgeGroup done\n",
      "clf CBOSS dataset DistalPhalanxOutlineCorrect done\n",
      "clf CBOSS dataset DistalPhalanxTW done\n",
      "clf CBOSS dataset ECG200 done\n",
      "clf CBOSS dataset ECGFiveDays done\n",
      "clf CBOSS dataset ItalyPowerDemand done\n",
      "clf CBOSS dataset MiddlePhalanxOutlineAgeGroup done\n",
      "clf CBOSS dataset MiddlePhalanxOutlineCorrect done\n",
      "clf CBOSS dataset MiddlePhalanxTW done\n",
      "clf CBOSS dataset OliveOil done\n",
      "clf CBOSS dataset Plane done\n",
      "clf CBOSS dataset ProximalPhalanxOutlineAgeGroup done\n",
      "clf CBOSS dataset ProximalPhalanxOutlineCorrect done\n",
      "clf CBOSS dataset ProximalPhalanxTW done\n",
      "clf CBOSS dataset SyntheticControl done\n",
      "clf CBOSS dataset TwoLeadECG done\n",
      "clf CBOSS dataset Wine done\n",
      "clf CBOSS done\n",
      "  Classifier  Accuracy  Fit-Time  Predict-Time total_feature_count\n",
      "0      CBOSS  0.841468  5.238014      8.203661                NULL\n",
      "clf CBOSS_Dilation dataset ArrowHead done\n",
      "clf CBOSS_Dilation dataset Beef done\n",
      "clf CBOSS_Dilation dataset BeetleFly done\n",
      "clf CBOSS_Dilation dataset BirdChicken done\n",
      "clf CBOSS_Dilation dataset Car done\n",
      "clf CBOSS_Dilation dataset CBF done\n",
      "clf CBOSS_Dilation dataset Coffee done\n",
      "clf CBOSS_Dilation dataset DiatomSizeReduction done\n",
      "clf CBOSS_Dilation dataset DistalPhalanxOutlineAgeGroup done\n",
      "clf CBOSS_Dilation dataset DistalPhalanxOutlineCorrect done\n",
      "clf CBOSS_Dilation dataset DistalPhalanxTW done\n",
      "clf CBOSS_Dilation dataset ECG200 done\n",
      "clf CBOSS_Dilation dataset ECGFiveDays done\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "slice step cannot be zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/vol/fob-vol3/mi20/hirschmi/dilation_project/dilation_evaluation/main.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgruenau6.informatik.hu-berlin.de/vol/fob-vol3/mi20/hirschmi/dilation_project/dilation_evaluation/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# z normalize data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgruenau6.informatik.hu-berlin.de/vol/fob-vol3/mi20/hirschmi/dilation_project/dilation_evaluation/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#X_train = zscore(X_train, axis=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgruenau6.informatik.hu-berlin.de/vol/fob-vol3/mi20/hirschmi/dilation_project/dilation_evaluation/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#X_test = zscore(X_test, axis=1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgruenau6.informatik.hu-berlin.de/vol/fob-vol3/mi20/hirschmi/dilation_project/dilation_evaluation/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgruenau6.informatik.hu-berlin.de/vol/fob-vol3/mi20/hirschmi/dilation_project/dilation_evaluation/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m clf[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgruenau6.informatik.hu-berlin.de/vol/fob-vol3/mi20/hirschmi/dilation_project/dilation_evaluation/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m fit_time \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m fit_time, \u001b[39m5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgruenau6.informatik.hu-berlin.de/vol/fob-vol3/mi20/hirschmi/dilation_project/dilation_evaluation/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m predict_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n",
      "File \u001b[0;32m~/dilation_project/sktime_dilation/sktime/classification/base.py:191\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mself.n_jobs must be set if capability:multithreading is True\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[39m# pass coerced and checked data to inner _fit\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n\u001b[1;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_time_ \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)) \u001b[39m-\u001b[39m start\n\u001b[1;32m    194\u001b[0m \u001b[39m# this should happen last\u001b[39;00m\n",
      "File \u001b[0;32m~/dilation_project/sktime_dilation/sktime/classification/dictionary_based/_cboss_dilation.py:297\u001b[0m, in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    295\u001b[0m boss\u001b[39m.\u001b[39mfit(X_subsample, y_subsample)\n\u001b[1;32m    296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_count \u001b[39m=\u001b[39m boss\u001b[39m.\u001b[39mfeature_count\n\u001b[0;32m--> 297\u001b[0m boss\u001b[39m.\u001b[39m_clean()\n\u001b[1;32m    298\u001b[0m boss\u001b[39m.\u001b[39m_subsample \u001b[39m=\u001b[39m subsample\n\u001b[1;32m    300\u001b[0m boss\u001b[39m.\u001b[39m_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_individual_train_acc(\n\u001b[1;32m    301\u001b[0m     boss,\n\u001b[1;32m    302\u001b[0m     y_subsample,\n\u001b[1;32m    303\u001b[0m     subsample_size,\n\u001b[1;32m    304\u001b[0m     \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m num_classifiers \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_ensemble_size \u001b[39melse\u001b[39;00m lowest_acc,\n\u001b[1;32m    305\u001b[0m )\n",
      "File \u001b[0;32m~/dilation_project/sktime_dilation/sktime/classification/base.py:191\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mself.n_jobs must be set if capability:multithreading is True\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[39m# pass coerced and checked data to inner _fit\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n\u001b[1;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_time_ \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)) \u001b[39m-\u001b[39m start\n\u001b[1;32m    194\u001b[0m \u001b[39m# this should happen last\u001b[39;00m\n",
      "File \u001b[0;32m~/dilation_project/sktime_dilation/sktime/classification/dictionary_based/_boss_dilation.py:612\u001b[0m, in \u001b[0;36mIndividualBOSSDilation._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[39m\"\"\"Fit a single boss classifier on n_instances cases (X,y).\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \n\u001b[1;32m    581\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mending in \"_\" and sets is_fitted flag to True.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer \u001b[39m=\u001b[39m SFAFast(\n\u001b[1;32m    599\u001b[0m     word_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_length,\n\u001b[1;32m    600\u001b[0m     alphabet_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malphabet_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m     max_feature_count\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_feature_count\n\u001b[1;32m    610\u001b[0m )\n\u001b[0;32m--> 612\u001b[0m X_dilated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation_size)\n\u001b[1;32m    614\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformed_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer\u001b[39m.\u001b[39mfit_transform(X_dilated, y)\n\u001b[1;32m    615\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformed_data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/dilation_project/sktime_dilation/sktime/classification/dictionary_based/_boss_dilation.py:572\u001b[0m, in \u001b[0;36mIndividualBOSSDilation.dilation\u001b[0;34m(X, d)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdilation\u001b[39m(X, d):\n\u001b[0;32m--> 572\u001b[0m     first \u001b[39m=\u001b[39m X[:, :, \u001b[39m0\u001b[39;49m::d]\n\u001b[1;32m    573\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, d):\n\u001b[1;32m    574\u001b[0m         second \u001b[39m=\u001b[39m X[:, :, i::d]\n",
      "\u001b[0;31mValueError\u001b[0m: slice step cannot be zero"
     ]
    }
   ],
   "source": [
    "\n",
    "for clf in clfs:\n",
    "    results = pd.DataFrame(columns=clf[2])\n",
    "    for dataset in datasets:\n",
    "        X_train, y_train = load_from_tsfile(dataset._train_path)\n",
    "        X_test, y_test = load_from_tsfile(dataset._test_path)\n",
    "\n",
    "        X_train = from_nested_to_3d_numpy(X_train)\n",
    "        X_test = from_nested_to_3d_numpy(X_test)\n",
    "\n",
    "        # Convert class labels to make sure they are between 0,n_classes\n",
    "        le = LabelEncoder().fit(y_train)\n",
    "        y_train = le.transform(y_train)\n",
    "        y_test = le.transform(y_test)\n",
    "        \n",
    "        # z normalize data\n",
    "        #X_train = zscore(X_train, axis=1)\n",
    "        #X_test = zscore(X_test, axis=1)\n",
    "\n",
    "        fit_time = time.process_time()\n",
    "        clf[0].fit(X_train, y_train)\n",
    "        fit_time = np.round(time.process_time() - fit_time, 5)\n",
    "\n",
    "        predict_time = time.process_time()\n",
    "        y_pred = clf[0].predict(X_test)\n",
    "        predict_time = np.round(time.process_time() - predict_time, 5)\n",
    "\n",
    "        acc = np.round(accuracy_score(y_test, y_pred), 5)\n",
    "        try:\n",
    "            feature_count = clf[0].feature_count * clf[0].num_of_random_dilations\n",
    "        except:\n",
    "            feature_count = \"NULL\"\n",
    "        results.loc[len(results)] = [clf[1], dataset.name, acc, fit_time, predict_time, feature_count] + clf[3]\n",
    "        \n",
    "        print(f\"clf {clf[1]} dataset {dataset.name} done\")\n",
    "\n",
    "    results_from_clf = results.loc[results[\"Classifier\"] == clf[1]]\n",
    "    av_acc = results_from_clf[\"Accuracy\"].mean()\n",
    "    av_fit_time = results_from_clf[\"Fit-Time\"].mean()\n",
    "    av_pred_time = results_from_clf[\"Predict-Time\"].mean()\n",
    "\n",
    "    av_results = pd.DataFrame(columns=clf[2])\n",
    "    av_results.loc[len(av_results)] = [clf[1], \"ALL_AVERAGE\", av_acc, av_fit_time, av_pred_time, feature_count] + clf[3]\n",
    "\n",
    "    results = pd.concat([results, av_results], ignore_index=True)\n",
    "\n",
    "    if not os.path.isfile(\"./results/\" + clf[1] + \"_results.csv\"):\n",
    "        results.to_csv(\"./results/\" + clf[1] + \"_results.csv\", header=True)\n",
    "    else:\n",
    "        results.to_csv(\"./results/\" + clf[1] + \"_results.csv\", mode='a', header=False)\n",
    "    print(f\"clf {clf[1]} done\")\n",
    "    print(av_results[['Classifier', 'Accuracy', 'Fit-Time', 'Predict-Time', 'total_feature_count']])\n",
    "    results = results[0:0]\n",
    "    av_results = av_results[0:0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bench8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a1cedb0727d0e5e0310af6dc3e70454c8b3344083c92b37c396a6163163aeab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
