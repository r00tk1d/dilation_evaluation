{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sktime.classification.dictionary_based import ContractableBOSS\n",
    "from sktime.classification.dictionary_based import ContractableBOSSDilation\n",
    "from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "from sktime.classification.dictionary_based import BOSSEnsembleDilation\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifierDilation\n",
    "#from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "#from sktime.classification.shapelet_based import ShapeletTransformClassifierDilation\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sktime.benchmarking.data import UEADataset, make_datasets\n",
    "\n",
    "from convst.classifiers import R_DST_Ridge\n",
    "from convst.utils.dataset_utils import load_sktime_dataset_split\n",
    "\n",
    "from sktime.datasets import load_from_tsfile\n",
    "from sktime.datatypes._panel._convert import from_nested_to_3d_numpy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_datasets = [\n",
    "    # 'ACSF1',\n",
    "    # 'Adiac',\n",
    "    # 'AllGestureWiimoteX',\n",
    "    # 'AllGestureWiimoteY',\n",
    "    # 'AllGestureWiimoteZ',\n",
    "    \"ArrowHead\",\n",
    "    \"Beef\",\n",
    "    \"BeetleFly\",\n",
    "    \"BirdChicken\",\n",
    "    # 'BME',\n",
    "    \"Car\",\n",
    "    \"CBF\",\n",
    "    # 'Chinatown',\n",
    "    # 'ChlorineConcentration',\n",
    "    # 'CinCECGTorso',\n",
    "    \"Coffee\",\n",
    "    # 'Computers',\n",
    "    # 'CricketX',\n",
    "    # 'CricketY',\n",
    "    # 'CricketZ',\n",
    "    # 'Crop',\n",
    "    \"DiatomSizeReduction\",\n",
    "    \"DistalPhalanxOutlineAgeGroup\",\n",
    "    \"DistalPhalanxOutlineCorrect\",\n",
    "    \"DistalPhalanxTW\",\n",
    "    # 'DodgerLoopDay',\n",
    "    # 'DodgerLoopGame',\n",
    "    # 'DodgerLoopWeekend',\n",
    "    # 'Earthquakes',\n",
    "    \"ECG200\",\n",
    "    # 'ECG5000',\n",
    "    \"ECGFiveDays\",\n",
    "    # 'ElectricDevices',\n",
    "    # 'EOGHorizontalSignal',\n",
    "    # 'EOGVerticalSignal',\n",
    "    # 'EthanolLevel',\n",
    "    # 'FaceAll',\n",
    "    # \"FaceFour\",\n",
    "    # 'FacesUCR',\n",
    "    # 'FiftyWords',\n",
    "    # 'Fish',\n",
    "    # 'FordA',\n",
    "    # 'FordB',\n",
    "    # 'FreezerRegularTrain',\n",
    "    # 'FreezerSmallTrain',\n",
    "    # 'Fungi',\n",
    "    # 'GestureMidAirD1',\n",
    "    # 'GestureMidAirD2',\n",
    "    # 'GestureMidAirD3',\n",
    "    # 'GesturePebbleZ1',\n",
    "    # 'GesturePebbleZ2',\n",
    "    #####\"Gun_Point\",\n",
    "    # 'GunPointAgeSpan',\n",
    "    # 'GunPointMaleVersusFemale',\n",
    "    # 'GunPointOldVersusYoung',\n",
    "    # 'Ham',\n",
    "    # 'HandOutlines',\n",
    "    # 'Haptics',\n",
    "    # 'Herring',\n",
    "    # 'HouseTwenty',\n",
    "    # 'InlineSkate',\n",
    "    # 'InsectEPGRegularTrain',\n",
    "    # 'InsectEPGSmallTrain',\n",
    "    # 'InsectWingbeatSound',\n",
    "    \"ItalyPowerDemand\",\n",
    "    # 'LargeKitchenAppliances',\n",
    "    # 'Lightning2',\n",
    "    # 'Lightning7',\n",
    "    # 'Mallat',\n",
    "    # 'Meat',\n",
    "    # 'MedicalImages',\n",
    "    # 'MelbournePedestrian',\n",
    "    \"MiddlePhalanxOutlineAgeGroup\",\n",
    "    \"MiddlePhalanxOutlineCorrect\",\n",
    "    \"MiddlePhalanxTW\",\n",
    "    # 'Missing_value_and_variable_length_datasets_adjusted',\n",
    "    # 'MixedShapesRegularTrain',\n",
    "    # 'MixedShapesSmallTrain',\n",
    "    # 'MoteStrain',\n",
    "    # 'NonInvasiveFetalECGThorax1',\n",
    "    # 'NonInvasiveFetalECGThorax2',\n",
    "    \"OliveOil\",\n",
    "    # 'OSULeaf',\n",
    "    # 'PhalangesOutlinesCorrect',\n",
    "    # 'Phoneme',\n",
    "    # 'PickupGestureWiimoteZ',\n",
    "    # 'PigAirwayPressure',\n",
    "    # 'PigArtPressure',\n",
    "    # 'PigCVP',\n",
    "    # 'PLAID',\n",
    "    \"Plane\",\n",
    "    # 'PowerCons',\n",
    "    \"ProximalPhalanxOutlineAgeGroup\",\n",
    "    \"ProximalPhalanxOutlineCorrect\",\n",
    "    \"ProximalPhalanxTW\",\n",
    "    # 'RefrigerationDevices',\n",
    "    # 'Rock',\n",
    "    # 'ScreenType',\n",
    "    # 'SemgHandGenderCh2',\n",
    "    # 'SemgHandMovementCh2',\n",
    "    # 'SemgHandSubjectCh2',\n",
    "    # 'ShakeGestureWiimoteZ',\n",
    "    # 'ShapeletSim',\n",
    "    # 'ShapesAll',\n",
    "    # 'SmallKitchenAppliances',\n",
    "    # 'SmoothSubspace',\n",
    "    ####\"SonyAIBORobot Surface\",\n",
    "    ####\"SonyAIBORobot SurfaceII\",\n",
    "    # 'StarLightCurves',\n",
    "    # 'Strawberry',\n",
    "    # 'SwedishLeaf',\n",
    "    # 'Symbols',\n",
    "    \"SyntheticControl\",\n",
    "    # 'ToeSegmentation1',\n",
    "    # 'ToeSegmentation2',\n",
    "    # 'Trace',\n",
    "    \"TwoLeadECG\",\n",
    "    # 'TwoPatterns',\n",
    "    # 'UMD',\n",
    "    # 'UWaveGestureLibraryAll',\n",
    "    # 'UWaveGestureLibraryX',\n",
    "    # 'UWaveGestureLibraryY',\n",
    "    # 'UWaveGestureLibraryZ',\n",
    "    # 'Wafer',\n",
    "    \"Wine\",\n",
    "    # 'WordSynonyms',\n",
    "    # 'Worms',\n",
    "    # 'WormsTwoClass',\n",
    "    # 'Yoga'\n",
    "\n",
    "    # \"DiatomSizeReduction\",\n",
    "    # \"DistalPhalanxOutlineAgeGroup\",\n",
    "    # \"DistalPhalanxOutlineCorrect\",\n",
    "    # \"DistalPhalanxTW\",\n",
    "    # \"ECG200\",\n",
    "    # \"ECGFiveDays\",\n",
    "    # \"MiddlePhalanxOutlineAgeGroup\",\n",
    "    # \"MiddlePhalanxOutlineCorrect\",\n",
    "    # \"MiddlePhalanxTW\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./Univariate_ts\"\n",
    "datasets = make_datasets(\n",
    "    path=DATA_PATH, dataset_cls=UEADataset, names=used_datasets\n",
    ")\n",
    "# [\"ArrowHead\", \"Car\", \"CBF\", \"Coffee\"]\n",
    "# [\"ArrowHead\"]\n",
    "\n",
    "# clfs hyperparameter:\n",
    "# ContractableBOSS\n",
    "cboss_num_of_random_dilations = 50 # TODO noch einbauen\n",
    "cboss_win_lengths = [32, 28, 24, 20, 16] #  picked randomly\n",
    "cboss_norm_options = [True, False]\n",
    "cboss_word_lengths = [8] \n",
    "cboss_alphabet_size = 2\n",
    "cboss_feature_selection = \"none\" # {\"chi2\", \"none\", \"random\"} Sets the feature selections strategy to be used. Chi2 reduces the number of words significantly and is thus much faster (preferred). Random also reduces the number significantly. None applies not feature selection and yields large bag of words, e.g. much memory may be needed.\n",
    "cboss_max_feature_count = 256 # default=256, If feature_selection=random is chosen, this parameter defines the number of randomly chosen unique words used.\n",
    "#n_parameter_samples = \n",
    "cboss_total_feature_count = cboss_num_of_random_dilations * min(cboss_alphabet_size ** cboss_word_lengths[0], cboss_max_feature_count) # sollte bei 10.000-30.000 liegen\n",
    "# TODO 10.000 features pro classifier im Ensemble? Oder Gesamt? (ich denke pro classifier im Ensemble)\n",
    "\n",
    "# def _unique_parameters(max_window, win_inc):\n",
    "#     possible_parameters = [\n",
    "#         [win_size, word_len, normalise]\n",
    "#         for n, normalise in enumerate(self._norm_options)\n",
    "#         for win_size in range(self.min_window, max_window + 1, win_inc)\n",
    "#         for g, word_len in enumerate(self._word_lengths)\n",
    "#     ]\n",
    "\n",
    "#     return possible_parameters\n",
    "\n",
    "cboss_results_cols = [        \n",
    "        \"Classifier\",\n",
    "        \"Dataset\",\n",
    "        \"Accuracy\",\n",
    "        \"Fit-Time\",\n",
    "        \"Predict-Time\",\n",
    "        \"total_feature_count\",\n",
    "\n",
    "        \"num_of_random_dilations\",\n",
    "        \"win_lengths\",\n",
    "        \"norm_options\",\n",
    "        \"word_lengths\",\n",
    "        \"alphabet_size\",\n",
    "        \"feature_selection\",\n",
    "        \"max_feature_count\"]\n",
    "\n",
    "\n",
    "\n",
    "# TSFDilation:\n",
    "tsf_min_interval = 3\n",
    "tsf_n_intervals_prop = 0.8\n",
    "# TODO relevant? tsf_num_of_random_dilations = 200\n",
    "\n",
    "tsf_results_cols = [        \n",
    "        \"Classifier\",\n",
    "        \"Dataset\",\n",
    "        \"Accuracy\",\n",
    "        \"Fit-Time\",\n",
    "        \"Predict-Time\",\n",
    "        \"total_feature_count\",\n",
    "        \n",
    "        \"min_interval\",\n",
    "        \"n_intervals_prop\",]\n",
    "\n",
    "#[ClassifierFunction, ClassifierName, result_col_names, hyperparameterForResultsCSV]\n",
    "cboss_params = {\n",
    "    \"num_of_random_dilations\": cboss_num_of_random_dilations, \n",
    "    \"win_lengths\": cboss_win_lengths, \n",
    "    \"norm_options\": cboss_norm_options, \n",
    "    \"word_lengths\": cboss_word_lengths,\n",
    "    \"alphabet_size\": cboss_alphabet_size,\n",
    "    \"feature_selection\": cboss_feature_selection,\n",
    "    \"max_feature_count\": cboss_max_feature_count,}\n",
    "clfs = [\n",
    "    [ContractableBOSS(), \"CBOSS\", cboss_results_cols, [\"NULL\", \"NULL\", \"[True, False]\", \"[16, 14, 12, 10, 8]\", \"4\", \"none\", \"256\"]],\n",
    "    [ContractableBOSSDilation(**cboss_params), \"CBOSS_Dilation\", cboss_results_cols, list(cboss_params.values())],\n",
    "    #[TimeSeriesForestClassifier(), \"TimeSeriesForest\", tsf_results_cols, [3, 1]],\n",
    "    #[TimeSeriesForestClassifierDilation(min_interval=tsf_min_interval, n_intervals_prop=tsf_n_intervals_prop), \"TimeSeriesForest_Dilation\",  tsf_results_cols, \\\n",
    "    #    [str(tsf_min_interval), str(tsf_n_intervals_prop)]],\n",
    "    \n",
    "    #[ShapeletTransformClassifier(estimator=RidgeClassifierCV()), \"ShapeletTransform+RidgeClassifier\", shapelet_results_cols, [\"DEFAULT\"]], \n",
    "    #[ShapeletTransformClassifier(), \"ShapeletTransform\", shapelet_results_cols, [\"DEFAULT\"]], # uses RandomForest from sktime\n",
    "    #[ShapeletTransformClassifierDilation(), \"ShapeletTransformDilation\", shapelet_results_cols, [\"EDIT ME\"]],\n",
    "    #[R_DST_Ridge(), \"RDST\", RDST_results_cols, \"DEFAULT\"], # uses RidgeClassifierCV from scikitlearn\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf CBOSS dataset Coffee done\n",
      "clf CBOSS dataset Beef done\n",
      "clf CBOSS dataset BirdChicken done\n",
      "clf CBOSS dataset BeetleFly done\n",
      "clf CBOSS dataset ECG200 done\n",
      "clf CBOSS dataset OliveOil done\n",
      "clf CBOSS dataset Wine done\n",
      "clf CBOSS dataset Plane done\n",
      "clf CBOSS dataset ArrowHead done\n",
      "clf CBOSS dataset DistalPhalanxOutlineAgeGroup done\n",
      "clf CBOSS dataset DistalPhalanxTW done\n",
      "clf CBOSS dataset MiddlePhalanxOutlineAgeGroup done\n",
      "clf CBOSS dataset DiatomSizeReduction done\n",
      "clf CBOSS dataset MiddlePhalanxTW done\n",
      "clf CBOSS dataset SyntheticControl done\n",
      "clf CBOSS dataset ProximalPhalanxOutlineAgeGroup done\n",
      "clf CBOSS dataset ProximalPhalanxTW done\n",
      "clf CBOSS dataset Car done\n",
      "clf CBOSS dataset MiddlePhalanxOutlineCorrect done\n",
      "clf CBOSS dataset DistalPhalanxOutlineCorrect done\n",
      "clf CBOSS dataset ProximalPhalanxOutlineCorrect done\n",
      "clf CBOSS dataset ItalyPowerDemand done\n",
      "clf CBOSS dataset ECGFiveDays done\n",
      "clf CBOSS dataset CBF done\n",
      "clf CBOSS dataset TwoLeadECG done\n",
      "clf CBOSS done\n",
      "  Classifier  Accuracy  Fit-Time  Predict-Time total_feature_count\n",
      "0      CBOSS  0.841297  6.187888      9.005826                NULL\n",
      "ERROR slice step cannot be zero for dataset ItalyPowerDemand clf CBOSS_Dilation\n",
      "clf CBOSS_Dilation dataset BeetleFly done\n",
      "clf CBOSS_Dilation dataset Beef done\n",
      "clf CBOSS_Dilation dataset Coffee done\n",
      "clf CBOSS_Dilation dataset BirdChicken done\n",
      "clf CBOSS_Dilation dataset OliveOil done\n",
      "clf CBOSS_Dilation dataset Wine done\n",
      "clf CBOSS_Dilation dataset ArrowHead done\n",
      "clf CBOSS_Dilation dataset ECG200 done\n",
      "clf CBOSS_Dilation dataset Car done\n",
      "clf CBOSS_Dilation dataset Plane done\n",
      "clf CBOSS_Dilation dataset DiatomSizeReduction done\n",
      "clf CBOSS_Dilation dataset DistalPhalanxOutlineAgeGroup done\n",
      "clf CBOSS_Dilation dataset DistalPhalanxTW done\n",
      "clf CBOSS_Dilation dataset MiddlePhalanxTW done\n",
      "clf CBOSS_Dilation dataset MiddlePhalanxOutlineAgeGroup done\n",
      "clf CBOSS_Dilation dataset SyntheticControl done\n",
      "clf CBOSS_Dilation dataset ProximalPhalanxOutlineAgeGroup done\n",
      "clf CBOSS_Dilation dataset ProximalPhalanxTW done\n",
      "clf CBOSS_Dilation dataset DistalPhalanxOutlineCorrect done\n",
      "clf CBOSS_Dilation dataset CBF done\n",
      "clf CBOSS_Dilation dataset ProximalPhalanxOutlineCorrect done\n",
      "clf CBOSS_Dilation dataset MiddlePhalanxOutlineCorrect done\n",
      "clf CBOSS_Dilation dataset ECGFiveDays done\n",
      "clf CBOSS_Dilation dataset TwoLeadECG done\n",
      "clf CBOSS_Dilation done\n",
      "       Classifier  Accuracy  Fit-Time  Predict-Time  total_feature_count\n",
      "0  CBOSS_Dilation    0.7806  6.707176      8.158035                12800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xml.sax.saxutils import prepare_input_source\n",
    "\n",
    "def benchmark(clf, dataset):\n",
    "    result = pd.DataFrame(columns=clf[2])\n",
    "    X_train, y_train = load_from_tsfile(dataset._train_path)\n",
    "    X_test, y_test = load_from_tsfile(dataset._test_path)\n",
    "\n",
    "    X_train = from_nested_to_3d_numpy(X_train)\n",
    "    X_test = from_nested_to_3d_numpy(X_test)\n",
    "\n",
    "    # Convert class labels to make sure they are between 0,n_classes\n",
    "    le = LabelEncoder().fit(y_train)\n",
    "    y_train = le.transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    # z normalize data\n",
    "    #X_train = zscore(X_train, axis=1)\n",
    "    #X_test = zscore(X_test, axis=1)\n",
    "\n",
    "    try:\n",
    "        fit_time = time.process_time()\n",
    "        clf[0].fit(X_train, y_train)\n",
    "        fit_time = np.round(time.process_time() - fit_time, 5)\n",
    "\n",
    "        predict_time = time.process_time()\n",
    "        y_pred = clf[0].predict(X_test)\n",
    "        predict_time = np.round(time.process_time() - predict_time, 5)\n",
    "        \n",
    "        acc = np.round(accuracy_score(y_test, y_pred), 5)\n",
    "        try:\n",
    "            feature_count = clf[0].feature_count * clf[0].num_of_random_dilations\n",
    "        except:\n",
    "            feature_count = \"NULL\"\n",
    "        result.loc[len(result)] = [clf[1], dataset.name, acc, fit_time, predict_time, feature_count] + clf[3]\n",
    "        \n",
    "        print(f\"clf {clf[1]} dataset {dataset.name} done\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {e} for dataset {dataset.name} clf {clf[1]}\")\n",
    "    return result\n",
    "\n",
    "for clf in clfs:\n",
    "    results = pd.concat(Parallel(n_jobs=-1)(delayed(benchmark)(clf, dataset)for dataset in datasets), ignore_index=True)\n",
    "    results_from_clf = results.loc[results[\"Classifier\"] == clf[1]]\n",
    "    av_acc = results_from_clf[\"Accuracy\"].mean()\n",
    "    av_fit_time = results_from_clf[\"Fit-Time\"].mean()\n",
    "    av_pred_time = results_from_clf[\"Predict-Time\"].mean()\n",
    "    feature_count = results_from_clf[\"total_feature_count\"].iat[0]\n",
    "\n",
    "    av_results = pd.DataFrame(columns=clf[2])\n",
    "    av_results.loc[len(av_results)] = [clf[1], \"ALL_AVERAGE\", av_acc, av_fit_time, av_pred_time, feature_count] + clf[3]\n",
    "\n",
    "    results = pd.concat([results, av_results], ignore_index=True)\n",
    "\n",
    "    if not os.path.isfile(\"./results/\" + clf[1] + \"_results.csv\"):\n",
    "        results.to_csv(\"./results/\" + clf[1] + \"_results.csv\", header=True)\n",
    "    else:\n",
    "        results.to_csv(\"./results/\" + clf[1] + \"_results.csv\", mode='a', header=False)\n",
    "    print(f\"clf {clf[1]} done\")\n",
    "    print(av_results[['Classifier', 'Accuracy', 'Fit-Time', 'Predict-Time', 'total_feature_count']])\n",
    "    results = results[0:0]\n",
    "    av_results = av_results[0:0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bench8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a1cedb0727d0e5e0310af6dc3e70454c8b3344083c92b37c396a6163163aeab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
